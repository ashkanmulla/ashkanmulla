{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0c88e16-5270-4b5d-91df-9aa4f37189c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "\n",
    "import warnings\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import gridspec\n",
    "import plotly.express as px\n",
    "from pandas import plotting\n",
    "import missingno as ms\n",
    "from sklearn.impute import SimpleImputer\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from itertools import product\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier, BaggingClassifier, StackingClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, roc_auc_score, recall_score, precision_score, f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cee00aeb-3746-40f1-8618-173813c28ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('Bank_01.xlsb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1201e82-92f2-4653-a272-c10b86774ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(715655, 157)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8ce9c7b-eaba-40f1-a8ce-355b2cd536ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Missing Values  Percentage Missing\n",
      "Id                                  0            0.000000\n",
      "AppsFlyer ID1                  419383           58.601281\n",
      "Client Code1                   112820           15.764579\n",
      "Email                          105137           14.691017\n",
      "Last Name                           0            0.000000\n",
      "...                               ...                 ...\n",
      "Device Model                   452320           63.203639\n",
      "UI                                  1            0.000140\n",
      "Lead Sub Status Final               0            0.000000\n",
      "Lead Stage                          0            0.000000\n",
      "bank_otput                          0            0.000000\n",
      "\n",
      "[157 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "missing_values = df.isna()  \n",
    "missing_count = missing_values.sum()\n",
    "percentage_missing = (missing_count / len(df)) * 100\n",
    "missing_info = pd.DataFrame({'Missing Values': missing_count, 'Percentage Missing': percentage_missing})\n",
    "\n",
    "print(missing_info) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "196f191f-d08e-4a59-918f-904bbf79b419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id                       218522\n",
      "AppsFlyer ID1            290487\n",
      "Client Code1             602426\n",
      "Email                    610099\n",
      "Last Name                 94403\n",
      "                          ...  \n",
      "Device Model               2065\n",
      "UI                       715654\n",
      "Lead Sub Status Final        40\n",
      "Lead Stage                    6\n",
      "bank_otput                    2\n",
      "Length: 157, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count unique values in each column\n",
    "unique_value_counts = df.nunique()\n",
    "\n",
    "# Display the counts\n",
    "print(unique_value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65f48bf7-dcbf-4cb8-8df8-63b4189882c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\c226231\\appdata\\local\\anaconda3\\envs\\pycaret\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\c226231\\appdata\\local\\anaconda3\\envs\\pycaret\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\c226231\\appdata\\local\\anaconda3\\envs\\pycaret\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\c226231\\appdata\\local\\anaconda3\\envs\\pycaret\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.20.3 in c:\\users\\c226231\\appdata\\local\\anaconda3\\envs\\pycaret\\lib\\site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\c226231\\appdata\\local\\anaconda3\\envs\\pycaret\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bbd8075-1e82-4cce-bf5d-39af0a5af4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_info.to_csv('missing_bank.csv')\n",
    "unique_value_counts.to_csv('unique_bank.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aae92da9-130a-4b9e-a3a4-1461ec802b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id\n",
      "AppsFlyer ID1\n",
      "Client Code1\n",
      "Email\n",
      "Last Name\n",
      "Mobile\n",
      "Lead Owner Name\n",
      "Lead Source\n",
      "Lead Status\n",
      "Lead Owner\n",
      "Created Time\n",
      "Modified By\n",
      "Modified Time\n",
      "Last Activity Time\n",
      "Lead Product\n",
      "Lead Sub Status\n",
      "Campaign\n",
      "Disposition\n",
      "Phone\n",
      "Referral Code\n",
      "Client Code\n",
      "utm_campaign\n",
      "utm_content\n",
      "utm_source\n",
      "utm_term\n",
      "utm_medium\n",
      "vt_keyword\n",
      "Permanent Address Proof\n",
      "Correspondence Address Proof\n",
      "PAN Card\n",
      "Photograph\n",
      "Income Proof\n",
      "Bank Account Proof\n",
      "eSign Eligibility\n",
      "KYC Option\n",
      "Photograph Approval\n",
      "Income Proof Approval\n",
      "Bank Account Proof Approval\n",
      "Address Approval\n",
      "PAN Card Approval\n",
      "eSign Done\n",
      "Address Proof Rejection\n",
      "Bank Account Proof Rejection\n",
      "Photograph Rejection\n",
      "PAN Card Rejection\n",
      "Income Proof Rejection\n",
      "Signature Rejection\n",
      "Signature Proof\n",
      "Signature Proof Approval\n",
      "City\n",
      "PAN Number\n",
      "Registration Source\n",
      "Keyword\n",
      "Lead Source Category\n",
      "OS Type\n",
      "Pickup Pincode\n",
      "Partner Client Code\n",
      "Total Calls\n",
      "Flag1\n",
      "Flag2\n",
      "DNC Customer\n",
      "Gender\n",
      "Date of Birth\n",
      "Age\n",
      "AppsFlyer ID\n",
      "Old-lead Owner\n",
      "Rand\n",
      "Lead Sub Status Temp\n",
      "Appsource\n",
      "AppsFlyer Channel\n",
      "App Release Version\n",
      "Sub Source\n",
      "AOD Response\n",
      "FTA Status\n",
      "Full Name\n",
      "Push To Aspect1\n",
      "Triggered Rule Name\n",
      "Client Activated Time\n",
      "Source Identifier URL\n",
      "Lead Source Sub Category\n",
      "Platform\n",
      "Mailer Sent\n",
      "Mailer Sent Time\n",
      "Account Type\n",
      "MSCLKID\n",
      "Primary Client Code\n",
      "Dev Field\n",
      "Referred By\n",
      "Eligible offer\n",
      "Refer & Earn Offer\n",
      "Historical CC\n",
      "Identifier\n",
      "Import Field\n",
      "Lead activated date\n",
      "Advertising ID\n",
      "Total Connected Calls\n",
      "Ad Name\n",
      "Ad Set Name\n",
      "Lead notes\n",
      "Interested in Algo Trading\n",
      "Site ID\n",
      "SMS Sent\n",
      "Lead Stage At Push\n",
      "CT API Response\n",
      "Lead Sub Status2\n",
      "Lead Sub Status ID\n",
      "Website Form Type\n",
      "GA Client ID\n",
      "Lead Owner Logs\n",
      "Lead Sub Status BF OAC\n",
      "Status Change Flag\n",
      "Website Section\n",
      "Lead Inactivity Flag\n",
      "AppsFlyer Push\n",
      "FireBase Push\n",
      "uppercase_Referral Code1\n",
      "NClient_Code\n",
      "LeadActDate\n",
      "PMTD\n",
      "CTD\n",
      "Account_Open\n",
      "Attributed Touch Type\n",
      "Attributed Touch Time\n",
      "Install Time\n",
      "Event Time\n",
      "Media Source\n",
      "Channel\n",
      "Campaign.1\n",
      "Campaign ID\n",
      "Adset\n",
      "Adset ID\n",
      "Ad\n",
      "Ad ID\n",
      "Ad Type\n",
      "Site ID.1\n",
      "Region\n",
      "Country Code\n",
      "State\n",
      "City.1\n",
      "Postal Code\n",
      "DMA\n",
      "IP\n",
      "Operator\n",
      "Carrier\n",
      "Language\n",
      "AppsFlyer ID.1\n",
      "Customer User ID\n",
      "Advertising ID.1\n",
      "Is Primary Attribution\n",
      "User Agent\n",
      "HTTP Referrer\n",
      "Original URL\n",
      "Device Model\n",
      "UI\n",
      "Lead Sub Status Final\n",
      "Lead Stage\n",
      "bank_otput\n",
      "target_final\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Function to calculate IV for discrete and conitnous variables on a binary target variable (\"Good\"/\"Bad\")\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "def calc_iv_num(df2,feature, target):\n",
    "    df=df2.copy()\n",
    "    print(feature)\n",
    "    lst = []\n",
    "    df[feature] = df[feature].replace([np.inf,-np.inf],np.nan)\n",
    "    df[feature] = df[feature].fillna(0)\n",
    "    df[feature] = pd.to_numeric(df[feature],errors='coerce')\n",
    "    #Split conitnous variables into max 10 bins based on percentile\n",
    "    df[feature+'_bin'] = pd.qcut(df[feature],q=10,duplicates='drop')\n",
    "    for i in range(df[feature+'_bin'].nunique()):\n",
    "        val = list(df[feature+'_bin'].unique())[i]\n",
    "        lst.append([feature,\n",
    "                   val,\n",
    "                   df[df[feature+'_bin']==val].count()[feature],\n",
    "                   df[(df[feature+'_bin']==val) & (df[target]=='Good')].count()[feature],\n",
    "                   df[(df[feature+'_bin']==val) & (df[target]=='Bad')].count()[feature]])\n",
    "    data = pd.DataFrame(lst,columns=['Variable','Value','All','Goods','Bads'])\n",
    "    data['Share'] = data['All'] / data['All'].sum()\n",
    "    data['Bad Rate'] = data['Bads'] / data['All']\n",
    "    data['Distribution Good'] = (data['All'] - data['Bads'])/(data['All'].sum() - data['Bads'].sum())\n",
    "    data['Distribution Bad'] = data['Bads']/data['Bads'].sum()\n",
    "    data['WoE']=np.log(data['Distribution Good']/data['Distribution Bad'])\n",
    "    data = data.replace({'WoE':{np.inf:0,-np.inf:0}})\n",
    "    data['IV_bin']=data['WoE']*(data['Distribution Good'] - data['Distribution Bad'])\n",
    "    data = data.sort_values(by = ['Variable','Value'],ascending = [True,True])\n",
    "    data.index = range(len(data.index))\n",
    "    data['IV']=data['IV_bin'].sum()\n",
    "    \n",
    "    return data\n",
    "\n",
    "def calc_iv_cat(df2,feature, target):\n",
    "    df=df2.copy()\n",
    "    print(feature)\n",
    "    lst = []\n",
    "    # Ignore features having more than 100 unique values\n",
    "    if df[feature].nunique()>100:\n",
    "        return pd.DataFrame()\n",
    "    df[feature] = df[feature].fillna(0)\n",
    "    df[feature+'_bin'] = df[feature]\n",
    "    for i in range(df[feature+'_bin'].nunique()):\n",
    "        val = list(df[feature+'_bin'].unique())[i]\n",
    "        lst.append([feature,\n",
    "                   val,\n",
    "                   df[df[feature+'_bin']==val].count()[feature],\n",
    "                   df[(df[feature+'_bin']==val) & (df[target]=='Good')].count()[feature],\n",
    "                   df[(df[feature+'_bin']==val) & (df[target]=='Bad')].count()[feature]])\n",
    "    data = pd.DataFrame(lst,columns=['Variable','Value','All','Goods','Bads'])\n",
    "    data['Share'] = data['All'] / data['All'].sum()\n",
    "    data['Bad Rate'] = data['Bads'] / data['All']\n",
    "    data['Distribution Good'] = (data['All'] - data['Bads'])/(data['All'].sum() - data['Bads'].sum())\n",
    "    data['Distribution Bad'] = data['Bads']/data['Bads'].sum()\n",
    "    data['WoE']=np.log(data['Distribution Good']/data['Distribution Bad'])\n",
    "    data = data.replace({'WoE':{np.inf:0,-np.inf:0}})\n",
    "    data['IV_bin']=data['WoE']*(data['Distribution Good'] - data['Distribution Bad'])\n",
    "    #data = data.sort_values(by = ['Variable','Value'],ascending = [True,True])\n",
    "    data.index = range(len(data.index))\n",
    "    data['IV']=data['IV_bin'].sum()\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def iterate_vars_iv(df,target):\n",
    "    data = pd.DataFrame()\n",
    "#     df=df[,2:]\n",
    "    varlist = list(df.columns)\n",
    "   # varlist = varlist[2:]\n",
    "    for i in varlist:\n",
    "        if df[str(i)].dtype == 'int' or  df[str(i)].dtype == 'float':\n",
    "            data = pd.concat([data,calc_iv_num(df,str(i),target)])\n",
    "        else:\n",
    "            data = pd.concat([data,calc_iv_cat(df,str(i),target)])\n",
    "    return data\n",
    "            \n",
    "    \n",
    "df['target_final'] = np.where(df.bank_otput == 0, \"Bad\",\"Good\")\n",
    "iv_output = iterate_vars_iv(df,'target_final')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ed74306",
   "metadata": {},
   "outputs": [],
   "source": [
    "iv_output.to_csv('IV_Output_bank.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e721d753",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
